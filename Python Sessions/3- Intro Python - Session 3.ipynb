{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112cde6a",
   "metadata": {},
   "source": [
    "# <center> Pandas (part 01) <center> \n",
    "    \n",
    "<img src = 'https://github.com/saeed-saffari/alzahra-workshop-spr2021/blob/main/lecture/PIC/Pandas.png?raw=true' \n",
    "     width = \"350\"\n",
    "     >\n",
    "    \n",
    "    \n",
    "In the previous sessions, we dove into detail on NumPy and its ``ndarray`` object and matplotlib, which provides efficient storage and manipulation of dense typed arrays and Visualization in Python.\n",
    "Here we'll build on this knowledge by looking in detail at the data structures provided by the Pandas library.\n",
    "Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a ``DataFrame``.\n",
    "``DataFrame``s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data.\n",
    "As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
    "\n",
    "As we saw, NumPy's ``ndarray`` data structure provides essential features for the type of clean, well-organized data typically seen in numerical computing tasks.\n",
    "While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us.\n",
    "Pandas, and in particular its ``Series`` and ``DataFrame`` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
    "\n",
    "To get started with pandas, you will need to get comfortable with its two workhorse data structures: Series and DataFrame. While they are not a universal solution for every problem, they provide a solid, easy-to-use basis for most applications.\n",
    "\n",
    "In this session, we will focus on the mechanics of using ``Series``, ``DataFrame``, and related structures effectively.\n",
    "\n",
    "    \n",
    "##  Installation\n",
    "\n",
    "- Conda install pandas\n",
    "- pip install pandas\n",
    "- pip install --upgrade pandas\n",
    "    \n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581d08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d15438",
   "metadata": {},
   "source": [
    "## 1. The Pandas Series Object\n",
    "\n",
    "A Pandas ``Series`` is a one-dimensional array of indexed data.\n",
    "It can be created from a list or array.\n",
    "\n",
    "- ``Series`` as generalized NumPy array <br><br>\n",
    "From what we've seen so far, it may look like the ``Series`` object is basically interchangeable with a one-dimensional NumPy array.\n",
    "The essential difference is the presence of the index: while the Numpy Array has an *implicitly defined* integer index used to access the values, the Pandas ``Series`` has an *explicitly defined* index associated with the values.<br><br>\n",
    "This explicit index definition gives the ``Series`` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
    "For example, if we wish, we can use strings as an index.\n",
    "\n",
    "\n",
    "- ``Series`` as specialized dictionary <br><br>\n",
    "In this way, you can think of a Pandas ``Series`` a bit like a specialization of a Python dictionary.\n",
    "A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a ``Series`` is a structure which maps typed keys to a set of typed values.<br>\n",
    "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas ``Series`` makes it much more efficient than Python dictionaries for certain operations.<br><br>\n",
    "The ``Series``-as-dictionary analogy can be made even more clear by constructing a ``Series`` object directly from a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d6515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66439838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ced69196",
   "metadata": {},
   "source": [
    "### 1.1 Sum Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81da9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f28e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fb86b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ba597b4",
   "metadata": {},
   "source": [
    "## 2. The Pandas DataFrame Object\n",
    "\n",
    "The next fundamental structure in Pandas is the ``DataFrame``.\n",
    "Like the ``Series`` object discussed in the previous section, the ``DataFrame`` can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.\n",
    "We'll now take a look at each of these perspectives.\n",
    "\n",
    "If a Series is an analog of a one-dimensional array with flexible indices, a DataFrame is an analog of a two-dimensional array with both flexible row indices and flexible column names. Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a DataFrame as a sequence of aligned Series objects. Here, by \"aligned\" we mean that they share the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e320f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080048bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95852eea",
   "metadata": {},
   "source": [
    "### 2.1 Columns, index, shape\n",
    "Like the ``Series`` object, the ``DataFrame`` has an ``index`` attribute that gives access to the index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685c39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b364198",
   "metadata": {},
   "source": [
    "Additionally, the ``DataFrame`` has a ``columns`` attribute, which is an ``columns`` object holding the column labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928db583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3c03ff",
   "metadata": {},
   "source": [
    "After all, the ``DataFrame`` has a ``shape`` attribute, which is tell us number of columns and index in out DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c386d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95f851f",
   "metadata": {},
   "source": [
    "Thus the ``DataFrame`` can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data.\n",
    "\n",
    "### 2.2 Call in table\n",
    "\n",
    "The individual ``Series`` that make up the columns of the ``DataFrame`` can be accessed via dictionary-style indexing of the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd70b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a2a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd08fa68",
   "metadata": {},
   "source": [
    "Equivalently, we can use attribute-style access with column names that are strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2dd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcdd00b4",
   "metadata": {},
   "source": [
    "### 2.3 Create new column\n",
    "\n",
    "You may add a new column to an existing pandas ``DataFrames`` just by assigning values to a new column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c438a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be01a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698a3762",
   "metadata": {},
   "source": [
    "### 2.4 Drop row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfde984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bd6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4be8a05",
   "metadata": {},
   "source": [
    "### 2.5 Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136ac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcdc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ee8201",
   "metadata": {},
   "source": [
    "### 2.6 Sort Value and index\n",
    "\n",
    "Sorting a dataset by some criterion is another important built-in operation. To sort lexicographically by row or column index, use the ``sort_index`` method, which returns a new, sorted object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ab812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef58cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef311782",
   "metadata": {},
   "source": [
    "The data is sorted in ascending order by default, but can be sorted in descending order, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6e5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19a72983",
   "metadata": {},
   "source": [
    "To sort a Series by its values, use its ``sort_values`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a81ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f231b533",
   "metadata": {},
   "source": [
    "### 2.7 call in table\n",
    "\n",
    "For ``DataFrame`` label-indexing on the rows, I introduce the special indexing operators ``loc`` and ``iloc``. They enable you to select a subset of the rows and columns from a DataFrame with NumPy-like notation using either axis labels (``loc``) or integers (``iloc``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e97687",
   "metadata": {},
   "source": [
    "#### iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52d92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d34c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205d5368",
   "metadata": {},
   "source": [
    "#### loc\n",
    "\n",
    "Similarly, using the ``loc`` indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb3e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b79e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852159cd",
   "metadata": {},
   "source": [
    "With this picture in mind, many familiar array-like observations can be done on the ``DataFrame`` itself.\n",
    "For example, we can transpose the full ``DataFrame`` to swap rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e6408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3956e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c22fa3e1",
   "metadata": {},
   "source": [
    "### 2.8 Filter\n",
    "\n",
    "Similarly, direct masking operations are also interpreted row-wise rather than column-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adad1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88880ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d43ab9",
   "metadata": {},
   "source": [
    "## 3. Reading data\n",
    "\n",
    "pandas features a number of functions for reading tabular data as a DataFrame object. \n",
    "\n",
    "|Function | Description|\n",
    "|---| --- |\n",
    "|read_csv|Load delimited data from a file, URL, or file-like object; use comma as default delimiter|\n",
    "|read_table|Load delimited data from a file, URL, or file-like object; use tab ('\\t') as default delimiter|\n",
    "|read_fwf|Read data in fixed-width column format (i.e., no delimiters)|\n",
    "|read_clipboard|Version of read_table that reads data from the clipboard; useful for converting tables from web pages|\n",
    "|read_excel|Read tabular data from an Excel XLS or XLSX file|\n",
    "|read_hdf|Read HDF5 files written by pandas|\n",
    "|read_html|Read all tables found in the given HTML document|\n",
    "|read_json|Read data from a JSON (JavaScript Object Notation) string representation|\n",
    "|read_msgpack|Read pandas data encoded using the MessagePack binary format|\n",
    "|read_pickle|Read an arbitrary object stored in Python pickle format|\n",
    "read_sas| Read a SAS dataset stored in one of the SAS system’s custom storage formats | \n",
    "read_sql|Read the results of a SQL query (using SQLAlchemy) as a pandas DataFrame|\n",
    "read_stata|Read a dataset from Stata file format|\n",
    "read_feather|Read the Feather binary file format|\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7eceb",
   "metadata": {},
   "source": [
    "### 3.1 Human development index (HDI)\n",
    "<b> Source:  [UNITED NATIONS DEVELOPMENT PROGRAMME (Human Development Reports)](http://hdr.undp.org/en/indicators/137506#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71ac5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac8e0dd",
   "metadata": {},
   "source": [
    "### 3.2 Real GDP Growth (Annual percent change) (IMF)\n",
    "<b> Source:  [International Monetary Fund (IMF)](https://www.imf.org/external/datamapper/NGDP_RPCH@WEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2dfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c768222d",
   "metadata": {},
   "source": [
    "### 3.3 GDP per capita, current prices (Purchasing power parity; international dollars per capita) (IMF)\n",
    "<b> Source:  [International Monetary Fund (IMF)](https://www.imf.org/external/datamapper/PPPPC@WEO/OEMDC/ADVEC/WEOWORLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc23f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0de21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f615d7df",
   "metadata": {},
   "source": [
    "# <center> Pandas (part 02) <center> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604143a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba41623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e854dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02986b4f",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Preparation\n",
    "### 1.1 Handling Missing Data (Na, NAN)\n",
    "\n",
    "Missing data occurs commonly in many data analysis applications. One of the goals of pandas is to make working with missing data as painless as possible. For example, all of the descriptive statistics on pandas objects exclude missing data by default.\n",
    "\n",
    "The way that missing data is represented in pandas objects is somewhat imperfect, but it is functional for a lot of users. For numeric data, pandas uses the floating-point value ``NaN`` (`Not a Number`) to represent missing data.\n",
    "\n",
    "In pandas, we’ve adopted a convention used in the R programming language by referring to missing data as `NA`, which stands for `not available`. In statistics applications, `NA` data may either be data that does not exist or that exists but was not observed (through problems with data collection, for example). When cleaning up data for analysis, it is often important to do analysis on the missing data itself to identify data collection problems or potential biases in the data caused by missing data.\n",
    "\n",
    "- **NA handling methods**\n",
    "\n",
    "|Argument | Description |\n",
    "| ---     | ---         |\n",
    "|dropna   |Filteaxis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate. |\n",
    "|fillna   | Fill in missing data with some value or using an interpolation method such as'ffill'or'bfill'. |\n",
    "|isnull   | Return boolean values indicating which values are missing/NA. |\n",
    "|notnull  | Negation ofisnull.|\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adbd229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abc</td>\n",
       "      <td>16</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>def</td>\n",
       "      <td>23</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ghi</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>xyz</td>\n",
       "      <td>25</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>333.0</td>\n",
       "      <td>ghj</td>\n",
       "      <td>27</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1   col2 col3 col4 col5\n",
       "0   1.0    NaN  abc   16  187\n",
       "1   2.0  555.0  def   23  160\n",
       "2   3.0    NaN  ghi   16  NaN\n",
       "3   4.0  444.0  xyz   25  202\n",
       "4   NaN  333.0  ghj   27  163"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1':[1,2,3,4,np.nan],\n",
    "    'col2':[np.nan,555,np.nan,444, 333],\n",
    "    'col3':['abc', 'def', 'ghi', 'xyz', 'ghj'],\n",
    "    'col4':['16', '23', '16', '25', '27'],\n",
    "    'col5':['187', '160', np.nan, '202', '163']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092643a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cf770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43960bb0",
   "metadata": {},
   "source": [
    "The `dropna` can be helpful that returns the Series or DataFrame with only the `non-null` data and index values.   \n",
    "Also you may want to drop rows or columns that are all `NA` or only those containing any `NA`s. `dropna` by default drops any row containing a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c37a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad63dd3",
   "metadata": {},
   "source": [
    "Passing `how='all'` will only drop rows that are all `NA`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22e2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73d025fc",
   "metadata": {},
   "source": [
    "To drop columns in the same way, pass `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faeb702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3260d20d",
   "metadata": {},
   "source": [
    "### 1.2 Filling In Missing Data\n",
    "\n",
    "Rather than filtering out missing data (and potentially discarding other data along with it), you may want to fill in the “holes” in any number of ways. For most purposes, the `fillna` method is the workhorse function to use. Calling `fillna` with a constant replaces missing values with that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97ca66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69270f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0083f8c",
   "metadata": {},
   "source": [
    "Calling `fillna` with a dict, you can use a different fill value for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3b5f72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b17676ed",
   "metadata": {},
   "source": [
    "### 1.3 Replacing Values\n",
    "\n",
    "Filling in missing data with the `fillna` method is a special case of more general value replacement. Now `replace` method provides a simpler and more flexible and general way to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d3465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75781112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76d02c73",
   "metadata": {},
   "source": [
    "## 2. Combining Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a99ba9",
   "metadata": {},
   "source": [
    "### Merge\n",
    "One essential feature offered by Pandas is its high-performance, in-memory join and merge operations.\n",
    "If you have ever worked with databases, you should be familiar with this type of data interaction.\n",
    "The main interface for this is the ``pd.merge`` function, and we'll see few examples of how this can work in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1048af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\n",
    "    'key': ['k0', 'k1', 'k2', 'k3'],\n",
    "    'A'  : ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B'  : ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "right = pd.DataFrame({\n",
    "    'key': ['k0', 'k1', 'k2', 'k4'],\n",
    "    'C'  : ['C0', 'C1', 'C2', 'C4'],\n",
    "    'D'  : ['D0', 'D1', 'D2', 'D4']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a01028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b8699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70391ad6",
   "metadata": {},
   "source": [
    "Most simply, you can explicitly specify the name of the key column using the on keyword, which takes a column name or a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224dc99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0c9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6dcee9c",
   "metadata": {},
   "source": [
    "## 3. Group by\n",
    "\n",
    "`DataFrame.groupby()` function is used to collect the identical data into groups and perform aggregate functions on the grouped data. Group by operation involves splitting the data, applying some functions, and finally aggregating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "652682a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Company': ['GOOG', 'GOOG','GOOG', 'MSFT', 'MSFT', 'FB', 'FB'],\n",
    "    'Person' : ['Sam', 'Charlie', 'John', 'Amy', 'Vanessa', 'Carl', 'Sarah'],\n",
    "    'Sales'  : [200, 120, 236, 340, 124, 243, 350]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6ffb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753b6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57c1f48a",
   "metadata": {},
   "source": [
    "## Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16cefd2",
   "metadata": {},
   "source": [
    "link: [link to download data (2019)](https://insights.stackoverflow.com/survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082c12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47390efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "942846f5",
   "metadata": {},
   "source": [
    "## 4. Statemodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e690366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5e820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d640f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7412303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044eda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# example DataFrame\n",
    "make_df('ABC', range(3))\n",
    "\n",
    "df1 = make_df('ABCD',range(4))\n",
    "df1\n",
    "\n",
    "df2 = make_df('ABCD', range(4,8))\n",
    "df2\n",
    "\n",
    "df3 = make_df('EFGH', range(0,4))\n",
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
